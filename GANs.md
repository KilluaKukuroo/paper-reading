
# Here we collect the recent papers, tutorials, etc. about GANs.

## tutorials
[Generative Neural Networks](https://dvl.in.tum.de/slides/adl4cv-ss20/5-GANs-1.pdf)<br>
[course page](https://dvl.in.tum.de/teaching/adl4cv-ss20/)<br>
2020, from  *Advanced Deep Learning for Computer Vision course*, **Technical University of Munich**. <br>

**contents**: <br>
- 介绍生成模型的分类，GAN只是里面的一个分支；
- 介绍GAN的评估方法（e.g., 看数据分布，训练一个分类器进行分类，saliency and diversity）；
- 多种GAN的损失函数;






## GAN synthetic data evaluation
[How good is my GAN?](https://eccv2018.org/openaccess/content_ECCV_2018/papers/Konstantin_Shmelkov_How_good_is_ECCV_2018_paper.pdf)<br>
2018, ECCV,   citation=78; <br>
**summary**:两种方法衡量生成图片的质量,base on image classificion；同时分析了，data augmentation；<br>
- train on synthetic data, test on real data; (GAN-train)
- train on real data, test on synthetic data; (GAN-test)

**contribution**:<br>
- 分析了利用生成数据做data augmentation 的影响：在一定数量的real image中加入一定量（50K）的生成数据，提高了ACC；
**（缺点：没有比较同样数量real images场景中，加入不同数量生成数据对结果的影响）--> 更正：在Fig4里面有对比，衡量diversity；**;


[An empirical study on evaluation metrics of generative adversarial networks](https://arxiv.org/pdf/1806.07755.pdf)<br>
2018 ICLR, citation=48, <br>
**summary**: 本文的核心，是评估多种evaluation metric，寻找最好的标准来指导GAN的学习和训练来生成更好的数据，不是寻找评估生成数据的最好标准。二者有重叠部分（生成数据多样性的考虑），
和不同的部分（是否考虑metric的计算开销）；

**method**：<br>
- 出发点：探究哪种情况下，哪种metric最好；哪些情况下，哪些metric会失效；
- 评估指标：**discriminability**, robustness to transformations, efficiency, detecting overfitting; <br> 
**result**: <br>
- MMD and 1-NN 效果最好；
**contribution**: <br>
- 总结了几种最流行的评估方法，Inception score, kernel MMD, Wasserstein distance, FID, 1-NN classifier; 
- 根据实验，得出结论：**In the convolutional space of a ResNet pre-trianed on ImageNet, the choice of feature space in which to compute variousmetrics is crucial**； 
- 

[PATE-GAN: GENERATING SYNTHETIC DATA WITH DIFFERENTIAL PRIVACY GUARANTEES](https://openreview.net/pdf?id=S1zk9iRqF7)<br>
2019 ICLR, citation=22; <br>
**summary**: 首先将*private aggregation of teacher ensembles (PATE)*引入到GANs，得到可以生成很强隐私性的GAN；接下来用一种新的角度评估生成的数据：在生成数据上训练测试算法
应该和在原始数据上得到同样的效果；<br>
**method**：<br>
- 提出三种evaluation methods: train on real, test on real; train on synthetic test on real ; train on synthetic test on synthetic; 

**problem**: <br>
- 没有说明为什么不用train on real and test on synthetic; <br>


[Pros and Cons of GAN Evaluation Measures](https://arxiv.org/pdf/1802.03446.pdf)<br>
2018 , citation=182; <br>
**summary**: 引用量最多的evaluating GANs的综述文章，总结了24 quantitative and 5 qualitative measures；将评估方法分为三种：定量、定性、人工判断；<br>
**method**: <br>
- **evaluating models rather than evaluating synthetic data; evaluating data is part of the task of evaluating the model;**



[Visual Evaluation of Generative Adversarial Networks for Time Series Data](https://arxiv.org/pdf/2001.00062.pdf)<br>
2019 AAAI, citation=0; <br>
**summary**: 大部分本文提出一种human-centered的可视化方法，评估生成的time-series数据；<br>
**method**： 

**contribution**: <br>
- guide a human to decide if data generated by a GAN algorithm can be used to build reliable and trustworthy AI models
- 基于两种可视化方法，让人类专家可以直观的比较oringinal data and generated time series data; 


[Are GANs Created Equal? A Large-Scale Study](https://papers.nips.cc/paper/7350-are-gans-created-equal-a-large-scale-study.pdf)<br>
2018 NIPS, citation=370; <br>
**summary**: 提出使用三个维度precision recall f1衡量GAN的性能；是下面(assessing-generative-models-via-precision-and-recall)的前面一个工作； <br>



[Assessing Generative Models via Precision and Recall](https://papers.nips.cc/paper/7769-assessing-generative-models-via-precision-and-recall.pdf)<br>
2018, NIPS， citation=65; <br>
**method**：<br>
- 使用inception network to embed the images;
**contribution**: <br>
- 分析了IS，FID等方法的缺点：利用one-dimensional score不能区分GAN失败的原因，e.g., 只能生成部分高质量数据，或者是生成所有数据但是质量低，这两种情形得到同样的FID score；
- 在image and text数据集上验证本文提出的方法；
- 有理论证明，
- **只需要有一个embedding vector, 本方法可以使用在任何modal**; 
- 把真实数据和生成数据的分布，划分为两个维度：precision-and-recall; 
- 提出了一种方法，compute precision and recall from samples from P and Q; 
- 本文算法不需要label，就像FID一样，但是IS需要label；
- 设计了Fa, F1/a的评估metric，和大家对VAE的观测一致：VAE生成的数据有更高的recall和很低的precision，也就是说VAE生成数据质量低，但是更少mode collapse; <br>


[Improved Techniques for Training GANs](https://arxiv.org/abs/1606.03498)<br>
2016 NIPS, citation= 3500; <br>
**summary**: 介绍了**Ineption score (IS)**作为评估GAN的标准;<br>

[Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/pdf/1611.07004.pdf)<br>
2018, citation=5600; <br>
**summary**: pixel2pixel, 图像-->图像生成。本文认为任何图像到图像的变换都可以用GAN得到同样的效果，借助CGAN的结构，提出通用的图片转换模型。
**method**: <br>
- 用两种方法评估quality of synthesized images: 1_亚马逊众包机器人，人工判断是真图片还是生成图片； 2)FCN在真实数据训练，在生成数据上测试做语义分割，根据结果打分；
**contribution**: <br>
- 不同的任务需要不同的loss function, **本文提出可以使用一个通用的方法处理多个任务**：图片上色，synthesize photos from label maps;

[Classification Accuracy Score for Conditional Generative Models](https://papers.nips.cc/paper/9393-classification-accuracy-score-for-conditional-generative-models.pdf)<br>
2019 NIPS, citation = 22; <br>
**summary**: 本文设计一个基于分类的方法，验证一个假设：deep generative models（VAE,autogressive model, GANs）学习到了数据的分布，生成的数据可以很好的用于下游任务。得到了令人惊讶的
结果；<br>
**core idea**: 如果模型生成的数据很好，那么train on synthetic data test on real data应该会有很好的结果(if the model capture the data distribution, performance on the downstream
task should be similar whether using original or synthesize data)；
**contribution**: <br>
- 用BigGAN-deep生成数据，用resnet50做分类器，发现**top-1, top-5 acc分别下降27.9%,41.6 compared with original data**;
- 本文发现，传统的IS，FID等evaluation metric，既不能预测classification accuracy score, 也不能用于除了GAN之外的其他生成模型；

[Measures to Evaluate Generative Adversarial Networks Based on Direct Analysis of Generated Images](https://arxiv.org/ftp/arxiv/papers/2002/2002.12345.pdf)<br>
2020, citation=0; <br>
**summary**: 和传统的IS(using classification performance)，FID(statistical metrics)不一样，本文直接分析GAN生成的图片来评估GAN模型，而不是把生成的图片输入到其他分类器。
**contribution**: <br>
- 提出了三种评估生成GAN生成图片的标准：creativity (不是复制原始图片), Inheritance(生成图片和原始图片某种意义上类似), diversity(生成图片彼此不一样); 

[A Classification–Based Study of Covariate Shift in GAN Distributions](http://proceedings.mlr.press/v80/santurkar18a/santurkar18a.pdf)<br>
2018 ICML,  citation = 17; <br>
**summary**: 提出一种基于分类的方法，评估the diversity of GAN; <br>
**problem**: <br>
- *covariate shift*: train set， test set的输入数据分布不同，导致训练集上学习的模型不能泛化到测试集，是最常见的一种dataset shift; 
- mode collapse: GAN生成一个或者少数几个类别的数据，discriminator无法判断真假，这样generator总是尝试生成这几类数据因为可以骗过discriminator，导致diversity of GAN收到损害；
- boundary distortion: 好像指的是GAN生成的数据在分布边界没有抓住真实分布的特点，导致了covariate shift，这种loss of diversity可使用基于分类的方法检测；
**contribution**: <br>
- 用基于classification的方法measure covariate shift;
- 验证了两种GAN带来的covariate shift：mode collapse, boundary distrotion;  
- 本文方法需要很少的人工监督，并且可以很简单的用来在其他数据集上评估其他的GAN模型；**通过在真实数据集训练分类模型M，用M在生成数据集上推理生成标签，类似于自动annotator**；
## time series generation

[Recurrent Conditional GANs for Time Series Sensor Modelling](http://roseyu.com/time-series-workshop/submissions/2019/timeseries-ICML19_paper_2.pdf)<br>
2019 ICML, citation=1; <br>


[Real-valued (Medical) Time Series Generation with Recurrent Conditional GANs](https://arxiv.org/abs/1706.02633)<br>
2017,   citation=133; <br>










